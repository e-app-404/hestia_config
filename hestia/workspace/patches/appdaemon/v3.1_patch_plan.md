# Exhaustive Patch Plan (executed now)

## 1) Executive summary & goals

* **Goal:** lock the stack to the v3.1 mapping contract, eliminate write collisions, harden APIs, and provide a bullet-proof reseed + export workflow.
* **Outcome:** deterministic writes, correct domain/room sets, robust endpoints (no stray 404/500), and a clean ops surface for future changes.

**In scope:** AppDaemon apps (`room_db_updater`, `activity_tracker`, `valetudo_default_activity`, `room_db_exporter`), mapping enforcement, runbooks, tests, and observability.
**Out of scope:** HA Core changes, MQTT broker tuning, non-room-db automations.

**Assumptions:**

* Host path for DB: `/addon_configs/a0d7b954_appdaemon/room_database.db`.
* In-container paths use `/config/...` (AppDaemon).
* v3.1 mapping file at `/config/www/area_mapping.yaml` is authoritative.

---

## 2) Surgical change list (by component)

### A) `room_db_updater`

1. **Admission control against mapping capabilities**

   * Validate `domain` is allowed for `room_id` (e.g., disallow ML in rooms without ML capability, VC without `segment_id`).
2. **Robust endpoint responses**

   * All endpoints return `(payload: dict, status: int)`; never empty/tuple mismatch.
3. **Write limiter harmonization**

   * Configurable limiter; add jitter (`±1s`) to reduce phase collisions; expose current limiter via health.
4. **Bulk reseed endpoint**

   * `POST /api/appdaemon/room_db_bulk_update` accepts an array of `{domain, room_id, config_data}`; processes with backoff per item.
5. **Mapping reload endpoint**

   * `POST /api/appdaemon/room_db_reload_mapping` → reloads YAML; returns counts and diff summary.
6. **Exporter write-after-update hook**

   * On successful upsert/delete, trigger `room_db_exporter.write_once()` (if present) or schedule soon.
7. **Idempotent upsert**

   * Single codepath: insert if missing else update `config_data`, `updated_at`, and keep `version` increment.

### B) `activity_tracker`

1. **Defensive result handling**

   * Catch HTML/non-JSON; normalize to `{status:"ok"|"retry"|"error", code, body}`.
2. **Backoff with jitter & dedupe**

   * If rate-limited or transient error, exponential backoff (2,4,8… max 60), jitter ±25%, dedupe identical writes within 5s.
3. **Toggle for reseed**

   * `enabled: true/false` config; skip writes when false (used during bulk reseed).
4. **Structured logging**

   * Include `room_id`, sensor, dedupe hit, retry count.

### C) `valetudo_default_activity`

1. **Respect mapping capabilities strictly**

   * Only VC writes for rooms with `segment_id`; never ML writes here.
2. **Optimistic writeback guard**

   * Default `optimistic_writeback: false`; make it opt-in to avoid unseen collisions.
3. **Write cadence alignment**

   * Align to updater limiter + jitter; expose dry-run toggle.

### D) `room_db_exporter`

1. **Reliable file export + HTTP GET**

   * Add `GET /api/appdaemon/room_db_export` that returns `(json, 200)` even on empty DB; never 500.
2. **Debounced write-after-update**

   * File write on update, debounced (e.g., 500ms) to coalesce bursts.
3. **Schema version stamp**

   * Include schema version, row counts by domain, mtime.

### E) Mapping conformance tools (tiny scripts)

1. **Validator CLI**: `validate_area_mapping.py`

   * Ensures every room with ML/VC capability is consistent; prints allowed domain/room matrix.
2. **Seeder CLI**: `seed_from_mapping.py`

   * Reads v3.1 and posts only allowed pairs; supports `--domain`, `--rooms`, `--dry-run`.

### F) QoL & hygiene

* Standardize logging prefix: `roomdb/<app>/<component>`.
* Add `Makefile` with `make backup`, `make reseed`, `make verify`, `make restore-rate`.
* Postman/Bruno collection for endpoints.

---

## 3) Concrete code patches (AppDaemon-style)

> Notes: use your existing class names; snippets show the exact mechanics Copilot should fold into the current files. Endpoints use AppDaemon’s `register_endpoint`.

### 3.1 `room_db_updater.py` — Admission control, robust endpoints, bulk, reload, exporter hook

```python
# inside initialize(self)
self.register_endpoint(self.health_ep, "room_db_health")
self.register_endpoint(self.test_ep, "room_db_test")
self.register_endpoint(self.update_config_ep, "room_db_update_config", methods=["POST"])
self.register_endpoint(self.bulk_update_ep, "room_db_bulk_update", methods=["POST"])
self.register_endpoint(self.reload_mapping_ep, "room_db_reload_mapping", methods=["POST"])
# optional: export passthrough if exporter not running
# self.register_endpoint(self.export_ep, "room_db_export")

def _load_mapping(self):
    path = self.args.get("canonical_mapping_file", "/config/www/area_mapping.yaml")
    self._mapping = load_yaml(path)  # handle exceptions
    self._allowed = build_allowed_matrix(self._mapping)  # {room_id: set(domains)}
    return dict(rooms=len(self._allowed))

def _is_allowed(self, domain, room_id):
    return room_id in self._allowed and domain in self._allowed[room_id]

def update_config_ep(self, request, data):
    try:
        domain = data.get("domain"); room_id = data.get("room_id"); cfg = data.get("config_data", {})
        if not domain or not room_id:
            return ({"status":"error","error":"domain and room_id required"}, 400)
        if not self._is_allowed(domain, room_id):
            return ({"status":"error","error": f"{domain}:{room_id} not allowed by mapping"}, 422)
        self._respect_write_limiter()   # includes jitter
        upsert_row(self.db_path, domain, room_id, cfg)
        self._export_async()            # debounce to 500ms
        return ({"status":"ok","room_id":room_id,"domain":domain}, 200)
    except RateLimited:
        return ({"status":"retry","error":"WRITE_RATE_LIMIT"}, 429)
    except Exception as e:
        self.error(f"update_config failed: {e}")
        return ({"status":"error","error":str(e)}, 500)

def bulk_update_ep(self, request, data):
    items = data if isinstance(data, list) else data.get("items", [])
    if not items: return ({"status":"error","error":"no items"}, 400)
    results = []
    for it in items:
        payload = {"domain":it.get("domain"), "room_id":it.get("room_id"), "config_data":it.get("config_data", {})}
        ok, res = self._one_update(payload)  # internally calls update path with backoff
        results.append(res)
    self._export_async()
    return ({"status":"ok","results":results}, 200)

def reload_mapping_ep(self, request, data):
    try:
        stats = self._load_mapping()
        return ({"status":"ok","mapping":stats}, 200)
    except Exception as e:
        return ({"status":"error","error":str(e)}, 500)

def _export_async(self):
    # if exporter is available, schedule its write_once
    try:
        self.run_in(lambda *_: self.call_service("appdaemon/call", app="room_db_exporter", function="write_once"), 0.5)
    except Exception:
        pass
```

**Limiter with jitter (shared helper):**

```python
def _respect_write_limiter(self):
    limit = int(self.args.get("write_rate_limit_seconds", 5))
    jitter = random.uniform(-1.0, 1.0)
    now = time.time()
    if now < self._next_write_ts:
        raise RateLimited()
    self._next_write_ts = now + max(1, limit + jitter)
```

### 3.2 `activity_tracker.py` — Defensive parsing, backoff, dedupe, toggle

```python
def _post_update(self, domain, room_id, cfg):
    if not self.args.get("enabled", True):
        self.log(f"skip write (disabled): {domain}:{room_id}", level="DEBUG")
        return True
    key = (domain, room_id, json.dumps(cfg, sort_keys=True))
    if key == self._last_key and time.time() - self._last_ts < 5:
        self.log("dedupe hit", level="DEBUG"); return True
    url = self.args.get("update_url", "http://a0d7b954-appdaemon:5050/api/appdaemon/room_db_update_config")
    payload = {"domain":domain, "room_id":room_id, "config_data":cfg}
    delay = 2
    for attempt in range(5):
        try:
            r = requests.post(url, json=payload, timeout=5)
            content_type = r.headers.get("Content-Type", "")
            data = r.json() if "application/json" in content_type else {"status":"error","code":r.status_code,"body":r.text[:200]}
        except Exception as e:
            data = {"status":"error","error":str(e)}
        if data.get("status") == "ok":
            self._last_key, self._last_ts = key, time.time()
            return True
        if r.status_code in (429, 500):
            time.sleep(delay + random.uniform(0, 2))
            delay = min(60, delay * 2)
            continue
        self.log(f"write failed: {data}", level="WARNING")
        return False
```

### 3.3 `valetudo_default_activity.py` — Capability guard, cadence

```python
def _maybe_write(self, room_id, cfg):
    if not self._allowed_vc(room_id):   # checks mapping segment_id presence
        self.log(f"skip VC write (not allowed by mapping): {room_id}", level="DEBUG")
        return
    # honor global limiter cadence + jitter
    time.sleep(self.args.get("rate_limit_seconds", 2) + random.uniform(0, 1))
    self._post_update("vacuum_control", room_id, cfg)
```

### 3.4 `room_db_exporter.py` — Solid GET + debounced file write

```python
def initialize(self):
    self.export_path = self.args.get("export_path", "/config/room_db_export.json")
    self.register_endpoint(self.export_ep, "room_db_export")
    self._debounce_handle = None

def export_ep(self, request, data):
    try:
        blob = self._collect()
        return (blob, 200)
    except Exception as e:
        self.error(f"export failed: {e}")
        return ({"status":"error","error":str(e)}, 500)

def write_once(self, *_):
    blob = self._collect()
    tmp = self.export_path + ".tmp"
    with open(tmp, "w") as f:
        json.dump(blob, f, indent=2)
    os.replace(tmp, self.export_path)
    return True

def write_debounced(self):
    if self._debounce_handle: self.cancel_timer(self._debounce_handle)
    self._debounce_handle = self.run_in(self.write_once, 0.5)

def _collect(self):
    rows = read_all_rows("/config/room_database.db")
    return {"status":"ok","schema_version":1,"counts":count_by_domain(rows),"by_domain":group_by_domain(rows)}
```

---

## 4) Ops runbooks (HA Terminal)

**Preflight & backups**

```sh
TS=$(date +%Y%m%d_%H%M%S)
cp -v /addon_configs/a0d7b954_appdaemon/room_database.db /addon_configs/a0d7b954_appdaemon/room_database.db.$TS.bak
cp -v /addon_configs/a0d7b954_appdaemon/apps/apps.yaml /addon_configs/a0d7b954_appdaemon/apps/apps.yaml.$TS.bak
cp -v /config/www/area_mapping.yaml /config/www/area_mapping.yaml.$TS.bak
```

**Rollout**

1. Apply code patches to respective app files under `/addon_configs/a0d7b954_appdaemon/apps/`.
2. Ensure mapping is v3.1 at `/config/www/area_mapping.yaml`.
3. Restart add-on:

```sh
ha addons restart a0d7b954_appdaemon
for i in {1..30}; do curl -s http://a0d7b954-appdaemon:5050/api/appdaemon/room_db_health | grep -q '"status": "healthy"' && break; sleep 2; done
```

**Validation**

```sh
# mapping reload works
curl -s -X POST http://a0d7b954-appdaemon:5050/api/appdaemon/room_db_reload_mapping | jq .
# bulk reseed example (safe)
curl -s -X POST -H 'Content-Type: application/json' \
  -d '[{"domain":"motion_lighting","room_id":"entrance","config_data":{"timeout":120,"illuminance_threshold":15}}]' \
  http://a0d7b954-appdaemon:5050/api/appdaemon/room_db_bulk_update | jq .
# exporter HTTP
curl -s http://a0d7b954-appdaemon:5050/api/appdaemon/room_db_export | jq '.by_domain'
# DB truth
sqlite3 /addon_configs/a0d7b954_appdaemon/room_database.db 'SELECT config_domain, room_id FROM room_configs ORDER BY 1,2;'
```

**Rollback**

```sh
cp -v /addon_configs/a0d7b954_appdaemon/room_database.db.$TS.bak /addon_configs/a0d7b954_appdaemon/room_database.db
cp -v /addon_configs/a0d7b954_appdaemon/apps/apps.yaml.$TS.bak /addon_configs/a0d7b954_appdaemon/apps/apps.yaml
ha addons restart a0d7b954_appdaemon
```

---

## 5) Test plan

**Unit (per app):**

* Mapper: build allowed matrix; deny/allow matrices for ML/VC.
* Updater: upsert idempotency; limiter jitter math; bulk endpoint array handling.
* Exporter: `_collect()` schema, write & replace.
* Activity tracker: parse variants (JSON, HTML), backoff & dedupe.

**Integration (AppDaemon harness):**

* Spin the apps, POST allowed and disallowed tuples, confirm `422` for disallowed, `200` for allowed.
* Trigger `reload_mapping`, then reseed a newly added room (e.g., entrance) → expect `200`.

**Black-box curl checks:**

```sh
curl -s http://a0d7b954-appdaemon:5050/api/appdaemon/room_db_health | jq '.status'
curl -s -X POST -H 'Content-Type: application/json' -d '{"domain":"motion_lighting","room_id":"not_a_room","config_data":{}}' http://a0d7b954-appdaemon:5050/api/appdaemon/room_db_update_config | jq .
curl -s http://a0d7b954-appdaemon:5050/api/appdaemon/room_db_export | jq '.counts'
```

**Binary acceptance criteria**

* Health is healthy; mapping reload endpoint returns room count ≥ v3.1 list.
* Disallowed pairs return `422` with helpful error.
* Bulk reseed succeeds with mixed results array but no 500s.
* Exporter GET returns JSON (never 500) and matches SQL.
* 10-minute log window: no repeated WRITE_RATE_LIMIT right after our own writes; other apps backoff correctly.

---

## 6) Observability

**Logging format**
`roomdb/<app>/<component> level=INFO event=... room_id=... domain=... attempt=... delay=...`

**Minimal metrics (in logs)**

* `writes.ok`, `writes.retry`, `writes.error` counts per 5min.
* `admission.denied` with reason.

**Error taxonomy**

* `WRITE_RATE_LIMIT` (429) → retry with backoff.
* `ADMISSION_DENIED` (422).
* `MAPPING_RELOAD_FAIL` (500).
* `EXPORT_FAIL` (500).

---

## 7) Risks & mitigations

* **Concurrent writers** → Harmonized limiter + jitter + backoff.
* **Mapping drift** → Reload endpoint; admission guard.
* **Exporter regressions** → Debounced writes + safe replace.
* **DB locks** → Upsert retries with short sleeps (50–100ms) on `sqlite3.OperationalError`.

---

## 8) Delta-contract (final)

```yaml
planned_change: "Harden room-db pipeline: mapping-guarded writes, bulk reseed, robust exporter, collision-free cadence"
deliverable:
  - Patched AppDaemon apps (4): updater, activity_tracker, valetudo_default_activity, exporter
  - Mapping validator + seeder scripts
  - Ops runbooks & tests
action_needed:
  - Apply code snippets; restart; validate via curl & sqlite3
rationale: "Eliminate collisions & drift; enforce mapping capabilities; reliable export; one-shot reseeds"
status: "proposed"
location:
  apps: "/addon_configs/a0d7b954_appdaemon/apps/"
  mapping: "/config/www/area_mapping.yaml"
  db: "/addon_configs/a0d7b954_appdaemon/room_database.db"
RACI_matrix:
  Responsible: Strategos
  Accountable: Evert
  Consulted: Copilot
  Informed: Stakeholders
acceptance_criteria:
  - "Admission control active (422 on disallowed pairs)"
  - "Exporter GET returns JSON with counts and by_domain"
  - "Bulk reseed endpoint processes arrays idempotently, no 500s"
  - "DB rows match v3.1 mapping exactly for ML/VC"
risk_assessment:
  - medium: concurrent writers; mitigated via limiter, jitter, backoff
rollback:
  - "Restore DB/apps.yaml from timestamped backups; restart add-on"
```

---

## 9) Compact checklist for Copilot

* [ ] Backup DB + apps.yaml.
* [ ] Patch `room_db_updater.py` with: admission control, robust endpoints, bulk, reload, exporter hook, limiter jitter.
* [ ] Patch `activity_tracker.py` with defensive parsing, backoff+jitter, dedupe, enabled toggle.
* [ ] Patch `valetudo_default_activity.py` with capability guard and cadence alignment; set `optimistic_writeback: false` by default.
* [ ] Patch `room_db_exporter.py` with stable GET + debounced file write.
* [ ] Confirm mapping is v3.1 on disk; test reload endpoint.
* [ ] Restart add-on; run curl tests; reseed (bulk) entrance ML; verify SQL & exporter JSON.
* [ ] Restore limiter to normal; monitor logs for 10 minutes; zero recurring collisions.

